%YAML:1.0

#common parameters
#support: 1 imu 1 cam; 1 imu 2 cam: 2 cam; 
imu: 1         
num_of_cam: 2

imu_topic: "/zedm/zed_node/imu/data_raw"
image0_topic: "/zedm/zed_node/left_raw/image_raw_gray"
image1_topic: "/zedm/zed_node/right_raw/image_raw_gray"
output_path: "/home/orin/Developments/vins_output/"

cam0_calib: "zedm_vga_left.yaml"
cam1_calib: "zedm_vga_right.yaml"
image_width: 672
image_height: 376

   
# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.


body_T_cam0: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data:  [-0.00868634, -0.00992536,  0.99991301,  0.03127054,
           -0.99996214, -0.00042279, -0.00869096,  0.0248833,
            0.00050902, -0.99995065, -0.00992132,  0.01035147,
            0.,          0.,          0.,          1.        ]
         #    kalibr (with zed initial base pose)
         #    [-0.01813762, -0.00064758,  0.99983529,  0.03146241,
         #   -0.99983129, -0.00289022, -0.01813942,  0.0159589,
         #    0.00290149, -0.99999561, -0.00059505,  0.01129763,
         #    0.,          0.,          0.,          1.        ]
   # [ -0.0119975, -0.0020119,  0.9999260, 0.002000,
   #          -0.9999260, -0.0019879, -0.0120015, 0.015000,
   #          0.0020119, -0.9999960, -0.0019879, 0.001710,
   #          0.000000, 0.000000, 0.000000, 1.000000 ]
   # cam -> imu
   # [0.999928, -0.011690, -0.002607, 0.002000,
   #    0.011696, 0.999929, -0.002340, -0.045000,
   #    0.002579, 0.002371, 0.999994, 0.001710,
   #    0.000000, 0.000000, 0.000000, 1.000000]
   ## imu -> cam
      # [0.999928, 0.011696, 0.002579, 0.002000,
      # -0.011690, 0.999929, 0.002371, 0.015000,
      # -0.002607, -0.002340, 0.999994, 0.001710,
      # 0.000000, 0.000000, 0.000000, 1.000000]
# [0.0046,     0.0301,    0.9995,     0.0942,
#          -1.0000,     -0.0042,    0.0047,    0.0160,
#           0.0044,    -0.9995,    0.0301,    -0.0489,
#          0.0,      0.0,    0.0,         1.0 ]
   # data: [0.0073,     0.0297,    0.9995,     0.0944,
   #       -1.0000,     -0.0045,    0.0047,    0.0162,
   #        0.0046,    -0.9995,    0.0297,    -0.0490,
   #       0.0,      0.0,    0.0,         1.0 ]
   # data: [0.0,     0.0,    1.0,     0.10771,
   #       -1.0,     0.0,    0.0,    0.029757,
   #        0.0,    -1.0,    0.0,    -0.056013,
   #       0.0,      0.0,    0.0,         1.0 ]

body_T_cam1: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data:  [ 0.00826232, -0.00601326,  0.99994779,  0.03023308,
            -0.99996575, -0.00054185,  0.00825921, -0.0382948,
            0.00049216, -0.99998177, -0.00601753,  0.010511,
            0.,          0.,          0.,          1.       ]
   
   # [ -0.0119975, -0.0020119,  0.9999260, 0.002000,
   #          -0.9999260, -0.0019879, -0.0120015, -0.045000,
   #          0.0020119, -0.9999960, -0.0019879, 0.001710,
   #          0.000000, 0.000000, 0.000000, 1.000000 ]
   # # [0.999928, -0.011690, -0.002607, 0.002000,
   #    0.011696, 0.999929, -0.002340, -0.045000,
   #    0.002579, 0.002371, 0.999994, 0.001710,
   #    0.000000, 0.000000, 0.000000, 1.000000]
   # #  [0.999928, 0.011696, 0.002579, 0.002000,
   #    -0.011690, 0.999929, 0.002371, -0.045000,
   #    -0.002607, -0.002340, 0.999994, 0.001710,
   #    0.000000, 0.000000, 0.000000, 1.000000]
   
  #  [  0.0073,     0.0310,     0.9995,      0.0946,
  #           -1.0,    -0.0042,     0.0074,     -0.0343,
  #           0.0044,     -0.9995,    0.0309,    -0.0487,
  #           0.0,      0.0,    0.0,          1.0 ]
   # data: [  0.0,     0.0,     1.0,      0.10729,
   #          -1.0,    0.0,     0.0,     -0.020241,
   #          0.0,     -1.0,    0.0,    -0.056233,
   #          0.0,      0.0,    0.0,          1.0 ]

#Multiple thread support
multiple_thread: 1
use_gpu: 1
use_gpu_acc_flow: 1

#feature traker paprameters
max_cnt: 150            # max feature number in feature tracking
min_dist: 40            # min distance between two features /// was 40 in real frlight tests
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image 
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1            # perform forward and backward optical flow to improve feature tracking accuracy

#optimization parameters
max_solver_time: 0.04  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0 # keyframe selection threshold (pixel)

#imu parameters       The more accurate parameters you provide, the better performance
# acc_n: 2.9898358129273046e-01 ## increased 100x
# gyr_n: 1.2461011016263906e-01 ## increased 1000x
# acc_w: 2.1784105274356966e-02 ## increased 100x
# gyr_w: 4.36575390318273e-02   ## increased 1000x

acc_n: 6.e-01 ## increased 200x
acc_w: 4.35e-02 ## increased 200x
# gyr_n: 2.5e-01 ## increased 2000x
# gyr_w: 8.72e-02   ## increased 2000x
gyr_n: 1.2461011016263906e-01 ## increased 1000x
gyr_w: 4.36575390318273e-02   ## increased 1000x
g_norm: 9.806549996         # gravity magnitude

#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu
td: 0.00056 #-0.0006055901927827886 ##-0.0085 ##-0.00425 ##-0.006265                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#loop closure parameters
load_previous_pose_graph: 0        # load and reuse previous pose graph; load from 'pose_graph_save_path'
pose_graph_save_path: "/home/orin/Developments/vins_output/pose_graph/" # save and load path
save_image: 1                   # save image in pose graph for visualization prupose; you can close this function by setting 0 


